
# skill_extractor_app

A simple FastAPI wrapper around our skill mapping pipeline.

The repo contains the reference skill lists, but models must be uploaded manually.
## Installation

### Step 1
First, create a virtual environment 

```bash
python3.10 -m venv venv
source venv/bin/activate
```
### Step 2 
Install dependencies.

```bash
pip install -r requirements.txt
```
### Step 3
The credentials (Azure OpenAI end point and API key) are kept in the [.env] file. Please, create it before go to the next step.

### Step 4 (Optional)
The file config.ini contains config variables necessary for the different modules (azure openai client, llm, gliner NER model, etc). The file can be regenerated by the script [configparser_generator.py](Scripts//configparser_generator.py)



## Scripts

- [get_skills.py](Scripts//get_skills.py) - This script is used to get skills from the skill lists. If indexed neofuzz models are not found, then the code can create models for hard and soft skills. References terms are under the Data folders.
-[get_skills2.py](Scripts//get_skill2s.py) - This script is a modified version of the above one. It used a single prompt (for now) and return domain specific and generic categories as well. 
- [extractor_app_3.py](Scripts//extractor_app_3.py) - This script is used to run the skill mapping pipeline.
- [configparser_generator.py](Scripts//configparser_generator.py) - This script is used to generate the config.ini file.
- [batch_skill_extraction.py](Scripts//batch_skill_extraction.py) - Collection of simple functions that can process text from jsonl, pandas df or csv. It needs to be simplified, unified, cleaned. 

## Notebooks

- [create_reference_data.ipynb](Notebooks//create_reference_data.ipynb) - This notebook generates term:[domain,domain_spec category, category] dictionaries based on the various taxonomies.

## Models

The models are stored in the Models folder. The models are used to extract skills from the job descriptions.
Due the size of the models, they are not included in the repo. The neofuzz model [dashboard_analytics_indexed_process.pkl] for mapping can be found at https://drive.google.com/file/d/1FKIPjM5tVIis8ksMFNyA3uSQ6GNE6nu0/view?usp=sharing
The skill reference dictionary [dashboard_analytics_terms2cat.pkl] that contains terms and their corresponding domains and categories can be found at https://drive.google.com/file/d/1BVBubo3RhmRqm_KSIAGCzRomo4zBOgr1/view?usp=sharing

## Usage

To use the skill extractor app, you need to upload the models and skill lists to the models folder.

### Example


## Deployment

To deploy this project locally, run

```bash
#launch fastapi
uvicorn --app-dir Scripts/ extractor_app_3:app --reload --port 8010
```

The service can be tested via curl:

```bash
curl -X 'POST' \
  'http://127.0.0.1:8010/predict/' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "textEntered": "We are looking to students who are enthusiastic about driving a sustainable, net-zero future, with a focus on developing strategies to reduce carbon emissions and optimize operational energy consumption of infrastructure, encompassing its construction, utilization and end of life phases, through effective carbon management and decarbonisation plans.Conduct research and analysis on carbon emissions inventories, reduction strategies, and regulatory requirements. Managing own workload to meet project deadlines.Reviewing project details and developing targets for sustainability.Reviewing documentation provided by project teams, assess this against the project’s targets and provide feedback or follow-up. Communicating sustainability requirements to internal and external team members. Producing reports providing advice and guidance to clients and project teams. Attending site visits to review progress against sustainability targets. Collaborate with multidisciplinary teams to develop carbon reduction targets and action plans for clients across different sectors.Strong academic background with coursework or experience in carbon accounting, greenhouse gas emissions, or related fields. A passion for innovation and problem solving. Humility, self-motivation and enthusiasm. Excellent communication, presentation and writing skills. An understanding of the construction industry and built environment."
}
```



Authentication is not set, port is exposed! 

## API Reference

You can check the API calls via FastAPI's auto-generated documentation:

[Documentation](http://127.0.0.1:8010/docs)


To test the backend module without sending input over the API, call get_skills2.py directly:

```bash
python3 get_skills2.py
```
  
This code takes a non-json compliant string as input and should run without any trouble. 

## Folder tree

```bash
.
├── config.ini
├── Data
│   ├── dashboard_analytics_terms2cat.pkl
│   ├── esco_terms2cat.pkl
│   ├── generic_greentech_terms2cat.pkl
│   ├── generic_terms2cat.pkl
│   ├── greentech_terms2cat.pkl
│   ├── hard_skills
│   │   ├── ESCO_hard_skills.csv
│   │   └── Lightcast_hard_skills.csv
│   ├── lightcast_terms2cat.pkl
│   └── soft_skills
│       ├── ESCO_soft_skills.csv
│       └── Lightcast_soft_skills.csv
├── Models
│   ├── Gliner
│   └── Neofuzz
│       ├── abodoo@20.77.56.119
│       └── dashboard_analytics_indexed_process.pkl
├── Notebooks
│   ├── create_reference_data.ipynb
│   └── quick_fix.ipynb
├── README.md
├── requirements.txt
└── Scripts
    ├── batch_skill_extraction.py
    ├── configparser_generator.py
    ├── extractor_app_3.py
    ├── get_skills2.py
    ├── get_skills.py
    ├── __pycache__
    │   ├── extractor_app_3.cpython-310.pyc
    │   ├── get_skills2.cpython-310.pyc
    │   └── get_skills.cpython-310.pyc
    └── test_get_skills.py

```

## Authors

- [gabor@abodoo.com]

